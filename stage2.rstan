functions {
    // ------------------------------------------------------------------
    //        helper func 
    // ------------------------------------------------------------------
    vector vpow(vector V, real p){
    
        vector[rows(V)]   Vh;
        int                N;
    
        N = rows(V);
        
        for (i in 1:N){
            Vh[i] = V[i]^p;
        }
        
        return Vh;
    }
    //-------------------------------------------------------------------
    // function is to recursively make a block row vector with scaled matrices
    // in each position (growing from left to right)
    //-------------------------------------------------------------------
    matrix block_row_scaled_matrix(matrix A, row_vector scale);
    matrix block_row_scaled_matrix(matrix A, row_vector scale){
        int   n;
        
        n = cols(scale);
        if (n==2){
            return append_col(scale[1]*A,scale[2]*A);
        }
        else{
            return append_col(scale[1]*A,block_row_scaled_matrix(A,tail(scale,n-1)));
        }
    }
    //-------------------------------------------------------------------
    // function is to recursively make a block row vector with matrices
    // from multidim array in each position (growing from top to bottom)
    //-------------------------------------------------------------------
    matrix block_col_matrix(matrix[] A);
    matrix block_col_matrix(matrix[] A){
        int   n;
        
        n = dims(A)[1];
        if (n==2){
            return append_row(A[1,,],A[2,,]);
        }
        else{
            return append_row(A[1,,],block_col_matrix(tail(A,n-1)));
        }
    }
    //-------------------------------------------------------------------
    // function to build the kronecher product using the defined recursive
    // formulations
    //-------------------------------------------------------------------
    
    matrix kron(matrix A, matrix B){
    
        matrix[rows(B),cols(A)*cols(B)]           vec[rows(A)];
        matrix[rows(A)*rows(B),cols(A)*cols(B)]            out;
        
        for (i in 1:rows(A)){
            vec[i,,] = block_row_scaled_matrix(B,sub_row(A,i,1,cols(A)));
        }
        
        out = block_col_matrix(vec);
        return out;
    
    }
    // ------------------------------------------------------------------
    //        nonlinear regression mean func - scaled power law type func
    // ------------------------------------------------------------------
    vector mean_func(int M,vector betax, real E, real Y, real K, vector eps, matrix scaling, vector yscaling){
        
        vector[M]         mu;
        real               f;
        vector[5]    betahat;
        real            Ehat;
        real            Yhat;
        real            Khat;
        vector[M]     epshat;
        
        
        // choose to scale things so that the derived betas' have some physical meaning
        // and we can interpret them / evaluate them against our intuition
        Ehat   = E*(scaling[2,1]-scaling[1,1]) + scaling[1,1];
        Yhat   = Y*(scaling[2,2]-scaling[1,2]) + scaling[1,2];
        Khat   = K*(scaling[2,3]-scaling[1,3]) + scaling[1,3];
        epshat   = eps*(scaling[2,4]-scaling[1,4]) + scaling[1,4];
        
        
        
        for (i in 1:M){
            f = (epshat[i]*Ehat*1e3/(1-0.3^2))^(-betax[5]);
            f = (f + (betax[1]*Yhat + betax[4]*Khat*1e3*(betax[2]+betax[3]*epshat[i]))^(-betax[5]))^(-(1/betax[5]));
            f = (f-yscaling[1])/yscaling[2];
            mu[i] = f;
        }
        
        return mu;
    }

    //-----------------------------------------------------------------------
	//      boxcox transformation
	//-----------------------------------------------------------------------
	vector boxcox(vector y,real lambda){
	
		vector[rows(y)]    yt;
		real             gam2;
		int                 N;
	
		N = rows(y);
		gam2 = min(y);
		
		if (min(y)<0){
			yt = y + fabs(gam2)*1.1;
		}
		if (fabs(lambda)<1e-8){
			for (i in 1:N){
				yt[i] = log(yt[i]);
			}
		}
		else{
			for (i in 1:N){
				yt[i] = (yt[i]^lambda - 1.0)/lambda;
			}
		}
	
	return yt;
	}
    //-----------------------------------------------------------------------
	//      Yeo-Johnson transformation
	//-----------------------------------------------------------------------
	vector YJ(vector y,real lambda){
	
		vector[rows(y)]    yt;
		int                 N;
	
		N = rows(y);
		
        for (i in 1:N){
        
            if ((lambda > 1e-8) && (y[i]>0.0)){
                yt[i] = ((y[i] + 1)^lambda - 1)/lambda;
            }
            else if ((lambda < 1e-8) && (y[i]>0.0)){
                yt[i] = log(y[i]+1);
            }
            else if ((lambda < (2-1e-8)) && (y[i]<0.0)){
                yt[i] = -((-y[i]+1)^(2-lambda)-1)/(2-lambda);
            }
            else{
                yt[i] = -log(-y[i]+1);
            }
        }
	return yt;
	}
  }
data {
  int<lower=1>                                N; // total number of points x in design
  int<lower=1>                                M; // total number of knots 
  int<lower=1>                               Me; // total number of experimental eps points
  vector[M*N]                             yComp; // computer experiments y's stacked up {y11,y12,...,y1N,y21,...,y2N,....yM1,...,yMN}
  vector[Me]                                yObs; // experimental observations
  matrix[N,3]                            design;
  vector[M]                                 eps; // computer exp eps
  vector[Me]                             epsexp; // exp eps
  matrix[2,4]                           scaling;
  vector[2]                            yscaling;
  matrix[N,N]                              Rinv;
  real                                  logdetR;
  real                                logdetSig;
  matrix[M,M]                            Siginv;
  vector[4]                                 phi;  
  vector[5]                               betax;
  vector[N*M]                                mu;
  vector[2]                            sigprior;
  vector[2]                         lambdaprior;
  vector[6]                              xprior;
  matrix[N,M]                               err;
  
}
parameters {
  real<lower=0,upper=1>                   X[3];
  real<lower=0>                        sig2eps;
  vector[3]                            epsbeta;
}


transformed parameters{
    vector[Me]                            err2;
    real                                 sX[3];
    matrix[Me,Me]                    inv_sig2e;
	vector[Me]                        sig2epsv;
    vector[3]                       epsbetahat;
	
    {
        vector[3]                               Xv;
        matrix[N,M]         Rinv_mult_E_mult_Reinv;
        vector[N]                               rx;
        matrix[3,N]                          dummy;
        vector[Me]                             mux;
        vector[M]                           dummye;
        matrix[M,Me]                            Re;
        vector[Me]                          dummy2;
        matrix[Me,3]                            Xe;
        
        epsbetahat = epsbeta;
        epsbetahat[2] = log(epsbeta[2]);
        epsbetahat[3] = log(epsbeta[3]);
        
        Rinv_mult_E_mult_Reinv=Rinv*(err*Siginv);

        Xe = rep_matrix(0,Me,3);
        Xe[,1] = rep_vector(1,Me);
        for (j in 2:3){
            Xe[,j] = vpow(epsexp,j-1);
        }
        sig2epsv = sig2eps*inv_logit(Xe*epsbetahat);
        
        inv_sig2e = diag_matrix(vpow(sig2epsv,-1));

        for (i in 1:3){
            Xv[i]=X[i];
            sX[i]=scaling[1,i] + (scaling[2,i]-scaling[1,i])*X[i];
        }

        //------------------------------------------
        //   mu and errors
        //------------------------------------------
        
        Re = rep_matrix(rep_vector(0,M),Me);
        dummy2 = mean_func(Me,betax, X[1], X[2], X[3], epsexp, scaling, yscaling);
        dummy = design' - rep_matrix(Xv,N);
        rx = exp(-(dummy' .* dummy')*head(phi,3));
        
        for (j in 1:Me){
            dummye = eps-rep_vector(epsexp[j],M);
            Re[,j] = exp(-phi[4]*(dummye .* dummye));
        }
        
        mux  = dummy2 + Re'*(Rinv_mult_E_mult_Reinv'*rx);
        err2=mux-yObs;
    }
}

model {
  
    //------------------------------------------
    //   setup the priors
    //------------------------------------------

    1/sig2eps ~ gamma(sigprior[1],sigprior[2]);

    X[1] ~ normal(xprior[1],xprior[2]) T[0,1];
    X[2] ~ normal(xprior[3],xprior[4]) T[0,1];
    X[3] ~ normal(xprior[5],xprior[6]) T[0,1];

  
    //------------------------------------------
    //   likelihood function
    //------------------------------------------
    target +=  -0.5*sum(log(vpow(diagonal(inv_sig2e),-1)));
    target += -0.5*err2'*(err2 .* diagonal(inv_sig2e));
	
	// if the constraints are violated then give it a really bad LL
    // kinda hacky but ok for now
   if (sX[1]<sX[3]){
        target += -1e6;
   }
}
